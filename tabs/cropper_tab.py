"""æ™ºæ…§è£åˆ‡åˆ†é ï¼šæ¨™ç±¤æ¨¡å¼ / è¦–è¦ºä¸»å‹•åµæ¸¬ (MediaPipe)"""
import os
from pathlib import Path

import gradio as gr

try:
    import cv2
    import numpy as np
    _HAS_CV2 = True
except ImportError:
    _HAS_CV2 = False

from . import shared
from src.cropper import run_crop
from src.auto_cropper import run_smart_crop_active, load_crop_parts, SUPPORTED_DETECTORS
from src.crop_engine import (
    load_crop_parts as load_engine_parts,
    run_crop_batch,
    run_calibration,
    run_multi_scale_test,
    run_detection_demo,
    run_precise_local_detect,
    run_crop_zoom_detect,
    process_roi,
    save_to_library,
    SUPPORTED_DETECTORS as ENGINE_DETECTORS,
)

_PROJECT_ROOT = Path(__file__).parent.parent
# è¼¸å‡ºè·¯å¾‘é–å®šåœ¨å°ˆæ¡ˆåº•ä¸‹ï¼Œé¿å…å™´åˆ° StabilityMatrix æ ¹ç›®éŒ„
DEFAULT_CROP_DEST = (_PROJECT_ROOT / "data" / "crop_output").resolve()


def _run_visual_active_stream(source, dest, size_val, padding_pct, min_size_val, target_part, full_auto,
                              manual_padding=None, manual_y_offset=None, manual_confidence=None):
    """è¦–è¦ºä¸»å‹•åµæ¸¬ï¼šåƒæ•¸é©…å‹•å‹ CropEngine æˆ–èˆŠç‰ˆ run_smart_crop_active"""
    if not source or not str(source).strip():
        yield "âŒ è«‹å…ˆé¸æ“‡ä¾†æºï¼ˆè³‡æ–™å¤¾æˆ– .zip å£“ç¸®æª”ï¼‰", []
        return

    dest = dest or str(DEFAULT_CROP_DEST)
    size_map = {"512Ã—512": 512, "768Ã—768": 768}
    size = size_map.get(str(size_val), 512)
    try:
        min_size = max(256, int(min_size_val)) if min_size_val not in (None, "") else 512
    except (TypeError, ValueError):
        min_size = 512
    target = str(target_part or "").strip()
    full = bool(full_auto)

    cfg = load_engine_parts()
    parts_list = [p for p in cfg.get("parts", []) if p.get("detector") in ENGINE_DETECTORS]
    part_by_id = {p["id"]: p for p in parts_list}
    use_engine = (target in part_by_id) or (full and parts_list)

    if use_engine:
        pad_override = float(manual_padding if manual_padding is not None else 20) / 100.0
        yoff_override = float(manual_y_offset if manual_y_offset is not None else 0) / 100.0
        conf_override = float(manual_confidence if manual_confidence is not None else 50) / 100.0
        to_run = [part_by_id[target]] if not full else parts_list
        log_lines = []
        all_previews = []
        for part_config in to_run:
            cfg = dict(part_config)
            cfg["padding"] = pad_override
            cfg["y_offset"] = yoff_override
            for log_line, previews, cur, tot in run_crop_batch(
                source, dest, cfg, crop_size=size, min_resolution=min_size,
                manual_confidence=conf_override
            ):
                log_lines.append(log_line)
                all_previews = previews
                yield "\n".join(log_lines), all_previews
    else:
        if Path(source).suffix.lower() == ".zip":
            yield "âŒ ZIP ä¾†æºåƒ…æ”¯æ´åƒæ•¸é©…å‹•æ¨¡å¼ï¼Œè«‹é¸æ“‡ã€Œæ‰‹éƒ¨ / æ‰‹æŒ‡ / è…³è¸åˆ°è…³å°– / ç²¾ç·»äº”å®˜ã€æˆ–å‹¾é¸å…¨è‡ªå‹•æƒæ", []
            return
        padding = max(0, min(1, float(padding_pct or 30) / 100))
        log_lines = []
        for log_line, previews in run_smart_crop_active(
            source, dest, crop_size=size, padding=padding, min_resolution=min_size,
            recursive=True, target_part=target, full_auto=full
        ):
            log_lines.append(log_line)
            yield "\n".join(log_lines), previews


def _run_crop_stream(source, dest, size_val, triggers_raw, target_part, padding_pct, min_size_val, strip_trigger):
    """åŸ·è¡Œè£åˆ‡ï¼Œä¸²æµæ—¥èªŒä¸¦å›å‚³é è¦½åœ–ã€‚yield (log_text, preview_list)ã€‚"""
    if not source or not str(source).strip():
        yield "âŒ è«‹å…ˆé¸æ“‡ä¾†æºï¼ˆè³‡æ–™å¤¾æˆ– .zip å£“ç¸®æª”ï¼‰", []
        return
    if Path(source).suffix.lower() == ".zip":
        yield "âŒ æ¨™ç±¤æ¨¡å¼ä¸æ”¯æ´ ZIPï¼Œè«‹æ”¹ç”¨è¦–è¦ºä¸»å‹•åµæ¸¬ä¸¦é¸æ“‡ç›®æ¨™éƒ¨ä½", []
        return

    dest = dest or str(DEFAULT_CROP_DEST)
    triggers = [t.strip() for t in (triggers_raw or "").split(",") if t.strip()] or ["Niyaniya", "Ibuki"]
    size_map = {"512Ã—512": 512, "768Ã—768": 768}
    size = size_map.get(str(size_val), 512)
    try:
        min_size = max(256, int(min_size_val)) if min_size_val not in (None, "") else 512
    except (TypeError, ValueError):
        min_size = 512
    padding = max(0, min(100, float(padding_pct))) if padding_pct is not None else 30
    use_mediapipe_hands = "æ‰‹éƒ¨" in str(target_part)

    previews = []

    def producer(log_cb):
        nonlocal previews
        cnt, pr = run_crop(
            source,
            dest,
            crop_size=size,
            min_resolution=min_size,
            padding_pct=padding,
            trigger_words=triggers if strip_trigger else [],
            use_mediapipe_hands=use_mediapipe_hands,
            use_edge_detection=not use_mediapipe_hands,
            target_part=str(target_part) if target_part else None,
            log_callback=log_cb,
            preview_count=8,
        )
        previews[:] = [(str(p), label) for p, label in pr]

    for text in shared.stream_from_log_callback(producer):
        yield text, previews


def _run_log_only(src, dst, size_label, triggers, target, pad, minsz, strip, mode, full_auto,
                  manual_pad=None, manual_yoff=None, manual_conf=None):
    """è¼¸å‡ºåˆ°æ—¥èªŒï¼›è¦–è¦ºæ¨¡å¼æ¯å¼µåœ–å³æ™‚å›å ±"""
    if mode and "è¦–è¦ºä¸»å‹•" in str(mode):
        for log_text, _ in _run_visual_active_stream(
            src, dst, size_label, pad, minsz, target, full_auto,
            manual_pad, manual_yoff, manual_conf
        ):
            yield log_text
    else:
        for log_text, _ in _run_crop_stream(src, dst, size_label, triggers, target, pad, minsz, strip):
            yield log_text


def _run_with_gallery(src, dst, size_label, triggers, target, pad, minsz, strip, mode, full_auto,
                     manual_pad=None, manual_yoff=None, manual_conf=None):
    """é›™è¼¸å‡ºï¼šæ—¥èªŒ + Gallery é è¦½"""
    if mode and "è¦–è¦ºä¸»å‹•" in str(mode):
        for log_text, previews in _run_visual_active_stream(
            src, dst, size_label, pad, minsz, target, full_auto,
            manual_pad, manual_yoff, manual_conf
        ):
            yield log_text, previews
    else:
        for log_text, previews in _run_crop_stream(src, dst, size_label, triggers, target, pad, minsz, strip):
            yield log_text, previews


def _calibration_preview(img, part, pad, yoff, conf):
    """æ ¡æ­£é è¦½ï¼šå›å‚³ (æ¨™è¨»å¾Œçš„åœ–ç‰‡, ç‹€æ…‹è¨Šæ¯)ã€‚"""
    if img is None:
        return None, ""
    pad_pct = float(pad or 20) / 100.0
    yoff_val = float(yoff or 0) / 100.0
    conf_val = float(conf or 50) / 100.0
    return run_calibration(img, str(part or "feet"), pad_pct, yoff_val, conf_val)


def render(defaults: dict, train_comps: dict):
    """å»ºç«‹æ™ºæ…§è£åˆ‡åˆ†é  (MediaPipe Powered)ã€‚"""
    with gr.Row():
        with gr.Column(scale=2):
            preview_canvas = gr.Image(
                label="æ ¡æ­£é è¦½ (Landmarks=ç¶ é», è£åˆ‡æ¡†=ç´…æ¡†)",
                type="numpy",
                height=360,
            )
            calibration_status = gr.Textbox(
                label="åµæ¸¬ç‹€æ…‹",
                value="",
                interactive=False,
            )
        with gr.Column(scale=1):
            calibration_test_img = gr.Image(
                label="æ¸¬è©¦åœ–ï¼ˆæ ¡æ­£ç”¨ï¼‰",
                type="numpy",
                height=160,
            )
            manual_padding = gr.Slider(
                minimum=0, maximum=100, value=20, step=1,
                label="Manual Padding (%)",
            )
            manual_y_offset = gr.Slider(
                minimum=-50, maximum=50, value=0, step=1,
                label="Manual Y-Offset",
            )
            manual_confidence = gr.Slider(
                minimum=1, maximum=100, value=50, step=1,
                label="Manual Confidence (%)",
            )
            cal_btn = gr.Button("æ ¡æ­£é è¦½", variant="secondary")
            multi_scale_btn = gr.Button("Test Multi-Scale Detection", variant="secondary")

    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### âœ‚ï¸ æ™ºæ…§è‚¢é«”æ”¶å‰²æ©Ÿ (MediaPipe Powered)\n**è¦–è¦ºä¸»å‹•åµæ¸¬**ï¼šä¾ç›®æ¨™éƒ¨ä½æˆ–ã€Œå…¨è‡ªå‹•æƒæã€åŒæ™‚åµæ¸¬æ‰‹ã€è…³ã€è‡‰ä¸¦è£åˆ‡ï¼Œè‡ªå‹•å¯«å…¥ hand_focus/feet_focus/face_focus æ¨™ç±¤ã€‚\nâ¬‡ åŸ·è¡Œçµæœé¡¯ç¤ºæ–¼é é¢ä¸‹æ–¹ã€ŒåŸ·è¡Œæ—¥èªŒã€")

            mode_radio = gr.Radio(
                choices=["è¦–è¦ºä¸»å‹•åµæ¸¬ (æ¨è–¦)", "æ¨™ç±¤æ¨¡å¼ (ä¾éƒ¨ä½)"],
                value="è¦–è¦ºä¸»å‹•åµæ¸¬ (æ¨è–¦)",
                label="è£åˆ‡æ¨¡å¼",
            )

            with gr.Row():
                source_dir = gr.Textbox(
                    label="é«˜å“è³ªç´ æä¾†æºï¼ˆè³‡æ–™å¤¾å« JPG/PNG/ZIPï¼‰",
                    value=defaults.get("cropper_source", defaults.get("train_data_dir", "")),
                    placeholder="E:/AI_Training/raw_mangaï¼ˆå¯å« .zipï¼‰",
                    scale=7,
                )
                gr.Button("è³‡æ–™å¤¾", scale=1).click(
                    fn=lambda x: shared.browse_folder(x),
                    inputs=[source_dir],
                    outputs=[source_dir],
                )
                gr.Button("ZIP", scale=1).click(
                    fn=lambda x: shared.browse_zip(x),
                    inputs=[source_dir],
                    outputs=[source_dir],
                )

            def _reload_parts_dropdown():
                cfg = load_engine_parts()
                choices = [(p.get("label", p["id"]), p["id"]) for p in cfg.get("parts", []) if p.get("detector") in ENGINE_DETECTORS]
                if not choices:
                    choices = [("æ‰‹éƒ¨ (Full Hand)", "hand"), ("è…³è¸åˆ°è…³å°–", "feet"), ("ç²¾ç·»äº”å®˜", "face")]
                return gr.update(choices=choices, value=choices[0][1])

            _parts_cfg = load_engine_parts()
            _part_choices = [(p.get("label", p["id"]), p["id"]) for p in _parts_cfg.get("parts", []) if p.get("detector") in ENGINE_DETECTORS]
            if not _part_choices:
                _part_choices = [("æ‰‹éƒ¨ (Hands)", "hand"), ("è…³éƒ¨ (Feet)", "feet"), ("è‡‰éƒ¨ (Face)", "face")]
            with gr.Row():
                target_part = gr.Dropdown(
                    choices=_part_choices,
                    value=_part_choices[0][1] if _part_choices else "hand",
                    label="ç›®æ¨™éƒ¨ä½ï¼ˆéå…¨è‡ªå‹•æ™‚ä½¿ç”¨ï¼‰",
                    scale=9,
                )
                reload_parts_btn = gr.Button("é‡è®€", scale=1)
            reload_parts_btn.click(fn=_reload_parts_dropdown, outputs=[target_part])
            full_auto_check = gr.Checkbox(
                label="å…¨è‡ªå‹•æƒæ",
                value=False,
            )

            with gr.Row():
                dest_dir = gr.Textbox(
                    label="è¼¸å‡ºè³‡æ–™å¤¾",
                    value=defaults.get("cropper_dest", str(DEFAULT_CROP_DEST)),
                    placeholder="è£åˆ‡çµæœè¼¸å‡ºä½ç½®",
                    scale=9,
                )
                gr.Button("ç€è¦½...", scale=1).click(
                    fn=lambda x: shared.browse_folder(x),
                    inputs=[dest_dir],
                    outputs=[dest_dir],
                )

            with gr.Row():
                padding = gr.Slider(
                    minimum=0, maximum=100, value=30,
                    label="é‚Šç·£æ“´å¼µ (%) â€” è¦–è¦ºæ¨¡å¼ï¼š0.3=30%",
                )
                min_size = gr.Number(label="æœ€å°è§£æåº¦è¦æ±‚", value=512)
                size_dropdown = gr.Dropdown(
                    label="è£åˆ‡å¤§å°ï¼ˆé•·è…¿æ¨¡å¼å›ºå®š 512Ã—768ï¼‰",
                    choices=["512Ã—512", "768Ã—768", "512Ã—768"],
                    value="512Ã—512",
                )

            strip_trigger = gr.Checkbox(
                label="è‡ªå‹•æ¸…ç†æ¨™ç±¤ (å»é™¤è§’è‰²è§¸ç™¼è©)",
                value=True,
            )
            trigger_input = gr.Textbox(
                label="è§¸ç™¼è©æ’é™¤",
                value=defaults.get("helper_trigger_words", "Niyaniya, Ibuki"),
                placeholder="å¾æ¨™ç±¤ä¸­ç§»é™¤çš„è§’è‰²è§¸ç™¼è©ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰",
            )
            crop_btn = gr.Button("ğŸš€ å•Ÿå‹• AI æ™ºæ…§è£åˆ‡", variant="primary")

        with gr.Column(scale=1):
            gr.Markdown("### æœ€æ–°è£åˆ‡æˆæœ")
            preview_gallery = gr.Gallery(
                label="è£åˆ‡æˆæœ",
                columns=5,
                height="400px",
                object_fit="contain",
            )

    _cal_inputs = [calibration_test_img, target_part, manual_padding, manual_y_offset, manual_confidence]
    _cal_outputs = [preview_canvas, calibration_status]

    def _multi_scale_test(img, part):
        if img is None:
            return None, ""
        return run_multi_scale_test(img, str(part or "feet"))

    multi_scale_btn.click(
        fn=_multi_scale_test,
        inputs=[calibration_test_img, target_part],
        outputs=[preview_canvas, calibration_status],
    )

    def _cal_with_status(img, part, pad, yoff, conf):
        out_img, status = _calibration_preview(img, part, pad, yoff, conf)
        return out_img, status or ""

    calibration_test_img.change(fn=_cal_with_status, inputs=_cal_inputs, outputs=_cal_outputs)
    target_part.change(fn=_cal_with_status, inputs=_cal_inputs, outputs=_cal_outputs)
    manual_padding.change(fn=_cal_with_status, inputs=_cal_inputs, outputs=_cal_outputs)
    manual_y_offset.change(fn=_cal_with_status, inputs=_cal_inputs, outputs=_cal_outputs)
    manual_confidence.change(fn=_cal_with_status, inputs=_cal_inputs, outputs=_cal_outputs)
    cal_btn.click(fn=_cal_with_status, inputs=_cal_inputs, outputs=_cal_outputs)

    bindings = [
        (crop_btn, _run_with_gallery, [
            source_dir, dest_dir, size_dropdown, trigger_input,
            target_part, padding, min_size, strip_trigger,
            mode_radio, full_auto_check,
            manual_padding, manual_y_offset, manual_confidence,
        ], preview_gallery),
    ]

    comps = {
        "cropper_source": source_dir,
        "cropper_dest": dest_dir,
        "cropper_preview": preview_gallery,
        "cropper_preview_canvas": preview_canvas,
    }
    return comps, bindings


def render_detection_demo_tab():
    """åµæ¸¬é©—è­‰èˆ‡è¦–è¦ºåŒ– Demoï¼šä¸å­˜æª”ã€ä¸è£åˆ‡ï¼Œç´”é è¦½èˆ‡åƒæ•¸æ ¡æ­£ã€‚"""
    gr.Markdown("### åµæ¸¬é©—è­‰èˆ‡è¦–è¦ºåŒ–\nä¸Šå‚³åœ–ç‰‡å¾Œ**é»æ“Šå…©æ¬¡**æ¡†é¸å€åŸŸï¼ˆç¬¬ä¸€æ¬¡=å·¦ä¸Šè§’ã€ç¬¬äºŒæ¬¡=å³ä¸‹è§’ï¼‰ï¼Œé¸å–å¾Œè‡ªå‹•ç•«è—æ¡†ä¸¦åŸ·è¡Œ AI åµæ¸¬ã€‚æˆ–ä½¿ç”¨ä¸‹æ–¹æŒ‰éˆ•åŸ·è¡Œåµæ¸¬ã€‚")
    coord_list_state = gr.State(value=[])
    with gr.Row():
        demo_input = gr.Image(
            label="åŸå§‹åœ–ï¼ˆé»å…©æ¬¡æ¡†é¸å€åŸŸï¼šå·¦ä¸Šâ†’å³ä¸‹ï¼‰",
            type="numpy",
            height=400,
            interactive=True,
        )
        demo_output = gr.Image(label="åµæ¸¬çµæœï¼ˆè—æ¡†=é¸å–å€åŸŸï¼Œç´…æ¡†=AI ä¿®æ­£ï¼‰", type="numpy", height=400)
    coord_display = gr.Textbox(label="é¸å–åº§æ¨™ (é»å…©æ¬¡å¾Œé¡¯ç¤º)", value="[]", interactive=False, visible=True)
    with gr.Accordion("é¸å–å€åŸŸï¼ˆé¸å¡«ï¼Œç²¾æº–åµæ¸¬ç”¨ï¼‰â€” è¼¸å…¥ x1,y1,x2,y2 æˆ–é»ã€Œå¡«å…¥æ•´å¼µåœ–ã€", open=False):
        with gr.Row():
            crop_x1 = gr.Number(label="x1", value=0, precision=0)
            crop_y1 = gr.Number(label="y1", value=0, precision=0)
            crop_x2 = gr.Number(label="x2", value=0, precision=0)
            crop_y2 = gr.Number(label="y2", value=0, precision=0)
        with gr.Row():
            btn_full = gr.Button("å¡«å…¥æ•´å¼µåœ–")
            btn_clear_select = gr.Button("æ¸…é™¤é¸å–")
    with gr.Row():
        detector_dropdown = gr.Dropdown(
            choices=["Face", "Hands", "Pose"],
            value="Face",
            label="åµæ¸¬å™¨",
        )
        confidence_slider = gr.Slider(
            minimum=0.1, maximum=0.5, value=0.3, step=0.05,
            label="Confidence",
        )
        resize_1024_check = gr.Checkbox(
            label="å•Ÿç”¨ 1024px é ç¸®æ”¾",
            value=True,
        )
        demo_btn = gr.Button("åŸ·è¡Œåµæ¸¬", variant="primary")
        precise_btn = gr.Button("é‡å°é¸å–å€åŸŸé€²è¡Œç²¾æº–åµæ¸¬", variant="secondary")

    def _run_demo(img, det, conf, resize_1024):
        if img is None:
            return None
        return run_detection_demo(img, det, conf, resize_1024)

    def _on_select(evt: gr.SelectData, img, coords, det, conf):
        if img is None:
            return None, [], "[]"
        try:
            x, y = int(evt.index[0]), int(evt.index[1])
        except (TypeError, IndexError, ValueError):
            return None, coords or [], str(coords or [])
        lst = list(coords or [])
        lst.extend([x, y])
        while len(lst) > 4:
            lst.pop(0)
            lst.pop(0)
        if len(lst) < 4:
            return None, lst, str(lst)
        x1, y1, x2, y2 = lst[0], lst[1], lst[2], lst[3]
        x1, x2 = min(x1, x2), max(x1, x2)
        y1, y2 = min(y1, y2), max(y1, y2)
        box = (x1, y1, x2, y2)
        annotated = run_precise_local_detect(img, det, conf, box)
        return annotated, lst, str(lst)

    def _clear_select():
        return [], 0, 0, 0, 0, "[]"

    def _run_precise(img, det, conf, cx1, cy1, cx2, cy2):
        if img is None:
            return None
        box = None
        try:
            v1, v2, v3, v4 = float(cx1 or 0), float(cy1 or 0), float(cx2 or 0), float(cy2 or 0)
            if v3 > v1 and v4 > v2:
                box = (int(v1), int(v2), int(v3), int(v4))
        except (TypeError, ValueError):
            pass
        return run_precise_local_detect(img, det, conf, box)

    def _fill_full(img):
        if img is None:
            return 0, 0, 0, 0
        h, w = img.shape[:2]
        return 0, 0, w, h

    demo_btn.click(
        fn=_run_demo,
        inputs=[demo_input, detector_dropdown, confidence_slider, resize_1024_check],
        outputs=[demo_output],
    )
    precise_btn.click(
        fn=_run_precise,
        inputs=[demo_input, detector_dropdown, confidence_slider, crop_x1, crop_y1, crop_x2, crop_y2],
        outputs=[demo_output],
    )
    btn_full.click(
        fn=_fill_full,
        inputs=[demo_input],
        outputs=[crop_x1, crop_y1, crop_x2, crop_y2],
    )
    btn_clear_select.click(
        fn=_clear_select,
        inputs=[],
        outputs=[coord_list_state, crop_x1, crop_y1, crop_x2, crop_y2, coord_display],
    )
    demo_input.select(
        fn=_on_select,
        inputs=[demo_input, coord_list_state, detector_dropdown, confidence_slider],
        outputs=[demo_output, coord_list_state, coord_display],
    )

    comps = {"demo_input": demo_input, "demo_output": demo_output}
    return comps, []


def render_crop_lib_demo_tab():
    """æ‰‹å‹•æ¡†é¸ + AI ä¿®æ­£ + åˆ†é¡å­˜æª”ï¼štool=select ç²å–åº§æ¨™ï¼Œè—è‰²æ‰‹å‹•å€â†’process_roiâ†’ç´…è‰² AI æ¡†ï¼Œå´é‚Šå³æ™‚é è¦½ã€‚"""
    gr.Markdown("### æ‰‹å‹•æ¡†é¸ + AI ä¿®æ­£ + åˆ†é¡å­˜æª”\næ”¾æ£„å½ˆçª—è£åˆ‡ï¼Œæ”¹ç”¨ **é»æ“Šå…©æ¬¡** æ¡†é¸å€åŸŸï¼ˆå·¦ä¸Šâ†’å³ä¸‹ï¼‰ã€‚åº§æ¨™ç‚ºè—è‰²æ‰‹å‹•å€ï¼Œç«‹å³åŸ·è¡Œ AI åµæ¸¬ä¸¦ç•«ç´…è‰²ä¿®æ­£æ¡†ã€‚å³å´å³æ™‚é¡¯ç¤ºè£åˆ‡é è¦½ï¼Œç¢ºèªå¾Œå­˜æª”ã€‚")
    crop_state = gr.State(value=None)
    coord_list_state = gr.State(value=[])
    image_list_state = gr.State(value=[])
    current_index_state = gr.State(value=0)
    with gr.Row():
        lib_folder = gr.Textbox(label="åœ–ç‰‡è³‡æ–™å¤¾", value="", placeholder="é¸æ“‡åŒ…å«åœ–ç‰‡çš„è³‡æ–™å¤¾è·¯å¾‘", scale=9)
        btn_browse = gr.Button("ç€è¦½", scale=1)
    with gr.Row():
        btn_load_folder = gr.Button("è¼‰å…¥è³‡æ–™å¤¾")
        btn_prev = gr.Button("â¬… ä¸Šä¸€å¼µ")
        btn_next = gr.Button("ä¸‹ä¸€å¼µ â¡")
        lib_counter = gr.Textbox(label="å¼µæ•¸", value="0 / 0", interactive=False, scale=1)
    with gr.Row():
        lib_input = gr.Image(
            label="åŸå§‹åœ–ï¼ˆé»å…©æ¬¡æ¡†é¸ï¼šå·¦ä¸Šâ†’å³ä¸‹ï¼‰",
            type="numpy",
            height=400,
            interactive=True,
        )
        with gr.Column(scale=1):
            lib_output = gr.Image(label="åµæ¸¬çµæœï¼ˆè—æ¡†=æ‰‹å‹•ï¼Œç´…æ¡†=AIï¼‰", type="numpy", height=340)
            lib_preview = gr.Image(
                label="è£åˆ‡é è¦½ï¼ˆå­˜æª”å‰ç¢ºèªå“è³ªï¼‰",
                type="numpy",
                height=200,
            )
    with gr.Row():
        lib_detector = gr.Dropdown(choices=["Face", "Hands", "Pose"], value="Face", label="åµæ¸¬å™¨")
        lib_confidence = gr.Slider(minimum=0.1, maximum=0.5, value=0.3, step=0.05, label="Confidence")
    with gr.Accordion("æ‰‹å‹•è¼¸å…¥åº§æ¨™ï¼ˆè‹¥é»é¸ç„¡æ•ˆï¼‰", open=False):
        with gr.Row():
            lib_x1 = gr.Number(label="x1", value=0, precision=0)
            lib_y1 = gr.Number(label="y1", value=0, precision=0)
            lib_x2 = gr.Number(label="x2", value=0, precision=0)
            lib_y2 = gr.Number(label="y2", value=0, precision=0)
        btn_manual = gr.Button("åŸ·è¡Œ process_roi")
    with gr.Row():
        btn_save_hand = gr.Button("ğŸ’¾ å­˜è‡³æ‰‹éƒ¨åº«", variant="secondary")
        btn_save_feet = gr.Button("ğŸ’¾ å­˜è‡³è…³éƒ¨åº«", variant="secondary")
        btn_save_face = gr.Button("ğŸ’¾ å­˜è‡³è‡‰éƒ¨åº«", variant="secondary")
    status_text = gr.Textbox(label="åµæ¸¬/å­˜æª”ç‹€æ…‹", interactive=False, lines=2)

    def _on_select(evt: gr.SelectData, img, coords, det, conf):
        if img is None:
            return None, None, None, [], "è«‹ä¸Šå‚³åœ–ç‰‡"
        try:
            x, y = int(evt.index[0]), int(evt.index[1])
        except (TypeError, IndexError, ValueError):
            return None, None, None, coords or [], "é¸å–åº§æ¨™å–å¾—å¤±æ•—"
        lst = list(coords or [])
        lst.extend([x, y])
        while len(lst) > 4:
            lst.pop(0)
            lst.pop(0)
        if len(lst) < 4:
            return None, None, None, lst, "è«‹é»ç¬¬äºŒæ¬¡å®Œæˆæ¡†é¸"
        x1, y1, x2, y2 = lst[0], lst[1], lst[2], lst[3]
        x1, x2 = min(x1, x2), max(x1, x2)
        y1, y2 = min(y1, y2), max(y1, y2)
        box = (x1, y1, x2, y2)
        annotated, preview, raw, msg = process_roi(img, box, det, conf)
        return annotated, preview, raw, lst, msg

    def _load_image(path: str):
        if not _HAS_CV2 or not path or not os.path.isfile(path):
            return None
        try:
            img = cv2.imread(path)
            if img is None:
                return None
            return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        except Exception:
            return None

    def _load_folder(folder_path):
        if not folder_path or not os.path.isdir(folder_path):
            return None, [], 0, None, None, None, [], "è«‹é¸æ“‡æœ‰æ•ˆè³‡æ–™å¤¾", "0 / 0"
        exts = {".jpg", ".jpeg", ".png", ".webp", ".bmp"}
        paths = []
        for f in sorted(os.listdir(folder_path)):
            if Path(f).suffix.lower() in exts:
                paths.append(os.path.join(folder_path, f))
        if not paths:
            return None, [], 0, None, None, None, [], "è³‡æ–™å¤¾å…§ç„¡æ”¯æ´åœ–ç‰‡ (jpg/png/webp)", "0 / 0"
        img = _load_image(paths[0])
        return img, paths, 0, None, None, None, [], f"å·²è¼‰å…¥ {len(paths)} å¼µ", f"1 / {len(paths)}"

    def _go_prev(img_list, idx):
        if not img_list:
            return None, 0, None, None, None, [], "", "0 / 0"
        new_idx = max(0, idx - 1)
        img = _load_image(img_list[new_idx])
        return img, new_idx, None, None, None, [], "", f"{new_idx + 1} / {len(img_list)}"

    def _go_next(img_list, idx):
        if not img_list:
            return None, 0, None, None, None, [], "", "0 / 0"
        new_idx = min(len(img_list) - 1, idx + 1)
        img = _load_image(img_list[new_idx])
        return img, new_idx, None, None, None, [], "", f"{new_idx + 1} / {len(img_list)}"

    def _save(lib_type, crop):
        return save_to_library(crop, lib_type)

    def _run_manual(img, det, conf, cx1, cy1, cx2, cy2):
        if img is None:
            return None, None, None, "è«‹ä¸Šå‚³åœ–ç‰‡"
        try:
            x1, y1, x2, y2 = int(cx1 or 0), int(cy1 or 0), int(cx2 or 0), int(cy2 or 0)
            if x2 <= x1 or y2 <= y1:
                return None, None, None, "è«‹è¼¸å…¥æœ‰æ•ˆåº§æ¨™ (x2>x1, y2>y1)"
        except (TypeError, ValueError):
            return None, None, None, "åº§æ¨™æ ¼å¼éŒ¯èª¤"
        box = (x1, y1, x2, y2)
        annotated, preview, raw, msg = process_roi(img, box, det, conf)
        return annotated, preview, raw, msg

    btn_browse.click(fn=lambda x: shared.browse_folder(x), inputs=[lib_folder], outputs=[lib_folder])
    btn_load_folder.click(
        fn=_load_folder,
        inputs=[lib_folder],
        outputs=[lib_input, image_list_state, current_index_state, lib_output, lib_preview, crop_state, coord_list_state, status_text, lib_counter],
    )
    btn_prev.click(
        fn=_go_prev,
        inputs=[image_list_state, current_index_state],
        outputs=[lib_input, current_index_state, lib_output, lib_preview, crop_state, coord_list_state, status_text, lib_counter],
    )
    btn_next.click(
        fn=_go_next,
        inputs=[image_list_state, current_index_state],
        outputs=[lib_input, current_index_state, lib_output, lib_preview, crop_state, coord_list_state, status_text, lib_counter],
    )
    lib_input.select(
        fn=_on_select,
        inputs=[lib_input, coord_list_state, lib_detector, lib_confidence],
        outputs=[lib_output, lib_preview, crop_state, coord_list_state, status_text],
    )
    btn_manual.click(
        fn=_run_manual,
        inputs=[lib_input, lib_detector, lib_confidence, lib_x1, lib_y1, lib_x2, lib_y2],
        outputs=[lib_output, lib_preview, crop_state, status_text],
    )
    btn_save_hand.click(fn=lambda c: _save("hand", c), inputs=[crop_state], outputs=[status_text])
    btn_save_feet.click(fn=lambda c: _save("feet", c), inputs=[crop_state], outputs=[status_text])
    btn_save_face.click(fn=lambda c: _save("face", c), inputs=[crop_state], outputs=[status_text])

    comps = {"crop_editor": lib_input, "crop_output": lib_output, "crop_preview": lib_preview, "crop_state": crop_state}
    return comps, []
