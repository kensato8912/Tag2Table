"""
è³‡æ–™åº«æ¨¡çµ„ï¼šè™•ç† JSON è®€å–ã€å¯«å…¥ã€åˆä½µ
åŒ…å«ï¼šconfigã€categoriesã€tag_mapã€æ¨™ç±¤è³‡æ–™åº«ã€è§’è‰²å¥—è£
"""
import os
import json
import shutil
from pathlib import Path
from collections import Counter
from datetime import datetime

# å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼ˆsrc çš„ä¸Šä¸€å±¤ï¼‰
_PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = _PROJECT_ROOT / "data"
TXT_OUTPUT_DIR = _PROJECT_ROOT / "txt"

def _ensure_data_dir():
    """ç¢ºä¿ data è³‡æ–™å¤¾å­˜åœ¨"""
    DATA_DIR.mkdir(parents=True, exist_ok=True)

def _ensure_txt_dir():
    """ç¢ºä¿ txt è¼¸å‡ºè³‡æ–™å¤¾å­˜åœ¨"""
    TXT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def _migrate_if_needed(old_path, new_path):
    """è‹¥æ–°ä½ç½®ç„¡æª”æ¡ˆä½†èˆŠä½ç½®æœ‰ï¼Œå‰‡æ¬é·ï¼ˆå‘å¾Œç›¸å®¹ï¼‰"""
    if not new_path.exists() and old_path.exists():
        try:
            _ensure_data_dir()
            shutil.copy2(old_path, new_path)
        except Exception:
            pass


def _init_from_example_if_needed(real_path, example_name):
    """è‹¥å¯¦æª”ä¸å­˜åœ¨ä½† .example.json å­˜åœ¨ï¼Œå‰‡å¾ç¯„ä¾‹è¤‡è£½å»ºç«‹"""
    example_path = DATA_DIR / example_name
    if not real_path.exists() and example_path.exists():
        try:
            _ensure_data_dir()
            shutil.copy2(example_path, real_path)
        except Exception:
            pass

# JSON è·¯å¾‘ï¼ˆå„ªå…ˆä½¿ç”¨ data/ï¼Œå•Ÿå‹•æ™‚æœƒæª¢æŸ¥èˆŠä½ç½®ä¸¦é·ç§»ï¼‰
CONFIG_FILE = DATA_DIR / "config.json"
TAGS_DB_FILE = DATA_DIR / "tags_db.json"
DB_FILE = DATA_DIR / "all_characters_tags.json"
CATEGORIES_FILE = DATA_DIR / "categories.json"
TAG_MAP_FILE = DATA_DIR / "tag_map.json"
PROMPT_PRESETS_FILE = DATA_DIR / "prompt_presets.json"

# å•Ÿå‹•æ™‚åŸ·è¡Œä¸€æ¬¡é·ç§»ï¼ˆèˆŠè·¯å¾‘ â†’ data/ï¼‰
for _old, _new in [
    (_PROJECT_ROOT / "config.json", CONFIG_FILE),
    (_PROJECT_ROOT / "tags_db.json", TAGS_DB_FILE),
    (_PROJECT_ROOT / "all_characters_tags.json", DB_FILE),
    (_PROJECT_ROOT / "categories.json", CATEGORIES_FILE),
    (_PROJECT_ROOT / "tag_map.json", TAG_MAP_FILE),
    (_PROJECT_ROOT / "prompt_presets.json", PROMPT_PRESETS_FILE),
]:
    _migrate_if_needed(_old, _new)

# è‹¥å¯¦æª”ä¸å­˜åœ¨ï¼Œå¾ .example.json è¤‡è£½å»ºç«‹ï¼ˆé¦–æ¬¡ clone å¾Œè‡ªå‹•åˆå§‹åŒ–ï¼‰
for _real, _example in [
    (CONFIG_FILE, "config.example.json"),
    (TAG_MAP_FILE, "tag_map.example.json"),
    (CATEGORIES_FILE, "categories.example.json"),
    (PROMPT_PRESETS_FILE, "prompt_presets.example.json"),
    (TAGS_DB_FILE, "tags_db.example.json"),
    (DB_FILE, "all_characters_tags.example.json"),
]:
    _init_from_example_if_needed(_real, _example)

# é è¨­åˆ†é¡ï¼ˆè‹¥ JSON ä¸å­˜åœ¨æ™‚ä½¿ç”¨ï¼‰
DEFAULT_CATEGORIES = {
    "èº«é«”ç‰¹å¾µ (Body)": ["hair", "eyes", "blush", "body", "thigh", "face", "skin", "lips", "breast",
                        "hand", "finger", "foot", "arm", "leg", "neck", "ear", "nose"],
    "è¡£æœé…ä»¶ (Clothing)": ["shirt", "skirt", "jacket", "hat", "gloves", "pantyhose", "uniform",
                            "shoes", "bow", "clothes", "dress", "sleeve", "collar", "ribbon", "cane", "beret"],
    "å§¿æ…‹å‹•ä½œ (Pose)": ["standing", "sitting", "lying", "holding", "looking", "smile", "open",
                        "spread", "raised", "bent", "crossed", "arms", "legs"],
    "èƒŒæ™¯ç’°å¢ƒ (Background)": ["background", "indoors", "outdoors", "scenery", "room", "white",
                              "simple", "sky", "cloud", "tree", "flower", "wall", "floor"],
    "å…‰ç·šé¢¨æ ¼ (Style)": ["light", "dark", "shadow", "glow", "sunlight", "sunset", "night",
                         "realistic", "anime", "solo", "masterpiece"],
    "è§’è‰²èˆ‡ä½œå“ (Character)": ["ibuki", "niyaniya", "professor", "blue archive", "blue_archive", "halo", "1girl", "2girls", "3girls"],
}


def load_categories():
    """å¾ categories.json è¼‰å…¥åˆ†é¡ï¼Œä¸å­˜åœ¨å‰‡å»ºç«‹é è¨­æª”ä¸¦å›å‚³"""
    try:
        if CATEGORIES_FILE.exists():
            with open(CATEGORIES_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, dict) and data:
                    return data
        save_categories(DEFAULT_CATEGORIES)
        return DEFAULT_CATEGORIES
    except Exception:
        return DEFAULT_CATEGORIES.copy()


def save_categories(categories):
    """å°‡åˆ†é¡å„²å­˜è‡³ categories.json"""
    try:
        _ensure_data_dir()
        with open(CATEGORIES_FILE, 'w', encoding='utf-8') as f:
            json.dump(categories, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


# è¼‰å…¥åˆ†é¡ï¼ˆå¯éš¨ categories.json æ›´æ–°ï¼‰
CATEGORIES = load_categories()


def load_tag_map():
    """å¾ tag_map.json è¼‰å…¥åŸºç¤ç¿»è­¯å°ç…§ï¼Œä¸å­˜åœ¨å‰‡å»ºç«‹é è¨­æª”ä¸¦å›å‚³"""
    default = {
        "niyaniya": "å°¼äºå°¼äº", "ibuki": "ä¼Šå¹", "1girl": "1åå¥³å­©", "solo": "å–®äºº",
        "blue archive": "è”šè—æª”æ¡ˆ", "blue_archive": "è”šè—æª”æ¡ˆ", "Blue Archive": "è”šè—æª”æ¡ˆ",
    }
    try:
        if TAG_MAP_FILE.exists():
            with open(TAG_MAP_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, dict):
                    return data
        save_tag_map(default)
        return default
    except Exception:
        return default.copy()


def save_tag_map(tag_map_dict):
    """å°‡åŸºç¤ç¿»è­¯å°ç…§å„²å­˜è‡³ tag_map.json"""
    try:
        _ensure_data_dir()
        with open(TAG_MAP_FILE, 'w', encoding='utf-8') as f:
            json.dump(tag_map_dict, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


# è¼‰å…¥åŸºç¤ç¿»è­¯ï¼ˆå¯éš¨ tag_map.json æ›´æ–°ï¼‰
tag_map = load_tag_map()


def load_config():
    """å¾ config.json è¼‰å…¥è¨­å®š"""
    try:
        if CONFIG_FILE.exists():
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception:
        pass
    return {}


def save_config(config):
    """å„²å­˜è¨­å®šè‡³ config.json"""
    try:
        _ensure_data_dir()
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


def load_existing_translations(json_path=None):
    """è®€å– JSON ä¸­å·²æœ‰çš„ç¿»è­¯ï¼Œä¸‹æ¬¡åŸ·è¡Œå¯è·³éå·²ç¿»è­¯çš„"""
    path = str(json_path or DB_FILE)
    try:
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return {item['en_tag']: item['zh_tag'] for item in data}
    except Exception:
        pass
    return {}


def load_tag_database(db_path=None):
    """è¼‰å…¥å®Œæ•´æ¨™ç±¤è³‡æ–™åº«ï¼Œå›å‚³ {en_tag: {zh_tag, category, count, characters, ...}}"""
    path = str(db_path or DB_FILE)
    try:
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                return {item['en_tag']: item for item in json.load(f)}
    except Exception:
        pass
    return {}


def get_category(tag):
    """æ ¹æ“šæ¨™ç±¤é—œéµå­—å›å‚³æ‰€å±¬åˆ†é¡ï¼ˆå« \\( \\) æ‹¬è™Ÿæ ¼å¼åµæ¸¬ï¼‰"""
    tag_lower = tag.lower()
    if "\\(" in tag or "\\)" in tag:
        return "è§’è‰²èˆ‡ä½œå“ (Character)"
    char_keywords = CATEGORIES.get("è§’è‰²èˆ‡ä½œå“ (Character)", [])
    if any(kw in tag_lower for kw in char_keywords):
        return "è§’è‰²èˆ‡ä½œå“ (Character)"
    for cat, keywords in CATEGORIES.items():
        if cat == "è§’è‰²èˆ‡ä½œå“ (Character)":
            continue
        if any(kw in tag_lower for kw in keywords):
            return cat
    return "å…¶ä»– (General)"


def save_tags_to_json(tag_counts, tag_map_dict, output_path=None, log_callback=None, category_getter=None):
    """å°‡æ¨™ç±¤ã€ç¿»è­¯ã€æ¬¡æ•¸ã€åˆ†é¡å­˜æˆ JSONï¼ˆå–®æ¬¡è¦†å¯«ï¼Œæ™ºæ…§åˆ†é¡ï¼‰"""
    def log(msg):
        if log_callback:
            log_callback(msg)
        else:
            print(msg)
    get_cat = category_getter or get_category
    path = str(output_path or TAGS_DB_FILE)
    try:
        final_data = []
        for tag, count in tag_counts.items():
            category = get_cat(tag)
            translation = tag_map_dict.get(tag, "æœªç¿»è­¯")
            final_data.append({
                "en_tag": tag,
                "zh_tag": translation,
                "count": count,
                "category": category
            })
        _ensure_data_dir()
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=4)
        log(f"âœ… æ¨™ç±¤è³‡æ–™åº«å·²å„²å­˜è‡³: {path}")
    except Exception as e:
        log(f"âš ï¸ å„²å­˜ JSON å¤±æ•—: {e}")


def update_tag_database(new_tags_list, db_path=None, character=None, log_callback=None):
    """
    åˆä½µæ›´æ–°æ¨™ç±¤è³‡æ–™åº«ï¼ˆç´¯åŠ æ¬¡æ•¸ã€æ›´æ–°ç¿»è­¯ã€è¨˜éŒ„è§’è‰²ï¼‰
    new_tags_list æ ¼å¼: [{"en_tag": "...", "zh_tag": "...", "count": 10, "category": "..."}, ...]
    character: æ­¤æ¬¡è™•ç†çš„è§’è‰²/è³‡æ–™å¤¾åç¨±ï¼Œæœƒå¯«å…¥ characters æ¸…å–®
    """
    def log(msg):
        if log_callback:
            log_callback(msg)
        else:
            print(msg)
    path = str(db_path or DB_FILE)
    try:
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                db = {item['en_tag']: item for item in json.load(f)}
        else:
            db = {}
        for item in new_tags_list:
            en = item['en_tag']
            if en in db:
                db[en]['count'] += item['count']
                db[en]['zh_tag'] = item['zh_tag']
                db[en]['category'] = item.get('category', db[en].get('category', 'å…¶ä»– (General)'))
                if character:
                    chars = db[en].setdefault('characters', [])
                    if character not in chars:
                        chars.append(character)
            else:
                entry = {k: v for k, v in item.items() if k != 'character'}
                entry['characters'] = [character] if character else []
                db[en] = entry
        _ensure_data_dir()
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(list(db.values()), f, ensure_ascii=False, indent=4)
        log(f"âœ… è³‡æ–™åº«å·²æ›´æ–°ï¼Œç›®å‰å…±æœ‰ {len(db)} å€‹ä¸é‡è¤‡æ¨™ç±¤ã€‚")
        show_db_status(path, log_callback=log_callback)
    except Exception as e:
        log(f"âš ï¸ æ›´æ–°è³‡æ–™åº«å¤±æ•—: {e}")


def show_db_status(db_file, log_callback=None):
    """é¡¯ç¤ºæ¨™ç±¤è³‡æ–™åº«ç‹€æ…‹å ±å‘Šï¼ˆæª”æ¡ˆå¤§å°ã€ç¸½æ¨™ç±¤æ•¸ã€åˆ†é¡çµ±è¨ˆï¼‰"""
    def out(msg):
        if log_callback:
            log_callback(msg)
        else:
            print(msg)
    db_path = str(db_file)
    if not os.path.exists(db_path):
        out("âŒ è³‡æ–™åº«æª”æ¡ˆå°šæœªå»ºç«‹ã€‚")
        return
    try:
        file_size = os.path.getsize(db_path) / (1024 * 1024)
        with open(db_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        total_tags = len(data)
        cat_stats = Counter([item.get('category', 'æœªåˆ†é¡') for item in data])
        out("\n" + "=" * 40)
        out("ğŸ“Š ã€æ¨™ç±¤è³‡æ–™åº«ç‹€æ…‹å ±å‘Šã€‘")
        out(f"ğŸ“‚ æª”æ¡ˆè·¯å¾‘: {os.path.abspath(db_path)}")
        out(f"ğŸ’¾ ä½”ç”¨å®¹é‡: {file_size:.4f} MB")
        out(f"ğŸ·ï¸ ç¸½æ¨™ç±¤æ•¸: {total_tags} æ¢")
        out("-" * 40)
        out("ğŸ—‚ï¸ åˆ†é¡çµ±è¨ˆ:")
        for cat, count in sorted(cat_stats.items(), key=lambda x: -x[1]):
            out(f"   â— {str(cat).ljust(20)} : {count} æ¢")
        out("=" * 40 + "\n")
    except Exception as e:
        out(f"âš ï¸ ç‹€æ…‹å ±å‘Šå¤±æ•—: {e}")


def scan_txt_files(root_folder, log_callback=None):
    """éè¿´æƒæè³‡æ–™å¤¾å…§æ‰€æœ‰çš„ .txt æ¨™ç±¤æª”"""
    txt_files = []
    root_path = Path(root_folder)
    if not root_path.exists():
        error_msg = f"âŒ éŒ¯èª¤ï¼šè³‡æ–™å¤¾ä¸å­˜åœ¨ - {root_folder}"
        if log_callback:
            log_callback(error_msg)
        else:
            print(error_msg)
        return txt_files
    for txt_file in root_path.rglob('*.txt'):
        txt_files.append(txt_file)
    msg = f"ğŸ“ æ‰¾åˆ° {len(txt_files)} å€‹ .txt æ¨™ç±¤æª”"
    if log_callback:
        log_callback(msg)
    else:
        print(msg)
    return txt_files


def extract_tags_from_file(file_path):
    """å¾å–®ä¸€ .txt æª”æ¡ˆä¸­æå–æ¨™ç±¤ï¼ˆæ”¯æ´é€—è™Ÿåˆ†éš”ï¼‰"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            tags = [t.strip() for t in content.split(',') if t.strip()]
            return tags
    except Exception as e:
        print(f"âš ï¸ è®€å–æª”æ¡ˆå¤±æ•— {file_path}: {e}")
        return []


def generate_folder_report(folder_path, report_file=None, db_path=None, log_callback=None, open_after=True):
    """é‡å°ç‰¹å®šè¨“ç·´è³‡æ–™å¤¾ç”Ÿæˆå ±å‘Šï¼ˆNotepad++ æ ¼å¼ï¼‰"""
    def out(msg):
        if log_callback:
            log_callback(msg)
        else:
            print(msg)
    path = Path(folder_path)
    out("ğŸ“‚ é‡æ–°è¼‰å…¥ JSON è³‡æ–™åº«ä»¥ç¢ºä¿ç‚ºæœ€æ–°...")
    db = load_tag_database(db_path)
    if not path.exists():
        out(f"âŒ æ‰¾ä¸åˆ°è·¯å¾‘: {folder_path}")
        return False
    txt_files = list(path.rglob('*.txt'))
    all_tags = []
    for f in txt_files:
        all_tags.extend(extract_tags_from_file(f))
    tag_counts = Counter(all_tags)
    if not tag_counts:
        out("âŒ æ­¤è³‡æ–™å¤¾æ²’æœ‰æ‰¾åˆ°ä»»ä½•æ¨™ç±¤")
        return False
    categorized_data = {}
    for tag, count in tag_counts.items():
        info = db.get(tag, {"zh_tag": "æœªç¿»è­¯", "category": get_category(tag)})
        cat = info.get('category', 'å…¶ä»– (General)')
        if cat not in categorized_data:
            categorized_data[cat] = []
        categorized_data[cat].append({
            "en": tag, "zh": info.get('zh_tag', 'æœªç¿»è­¯'), "count": count
        })
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    out_path = str(report_file or TXT_OUTPUT_DIR / "Current_Folder_Tag_Report.txt")
    report = [
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
        "â•‘             ç•¶å‰è¨“ç·´è³‡æ–™å¤¾æ¨™ç±¤åˆ†æå ±å‘Š (Notepad++)             â•‘",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
        f"  è³‡æ–™å¤¾: {path.resolve()}",
        f"  åˆ†ææ™‚é–“: {now}",
        f"  æ¨™ç±¤æª”æ•¸: {len(txt_files)} å¼µ",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
    ]
    cat_order = ["è§’è‰²èˆ‡ä½œå“ (Character)"] + [c for c in CATEGORIES.keys() if c != "è§’è‰²èˆ‡ä½œå“ (Character)"] + ["å…¶ä»– (General)"]
    for cat in cat_order:
        if cat not in categorized_data:
            continue
        report.append(f"â— {cat}")
        report.append("-" * 75)
        report.append(f"{'è‹±æ–‡æ¨™ç±¤ (Tag)'.ljust(35)} | {'æ¬¡æ•¸'.ljust(6)} | {'ä¸­æ–‡ç¿»è­¯'}")
        report.append("-" * 75)
        items = sorted(categorized_data[cat], key=lambda x: x['count'], reverse=True)
        for item in items:
            report.append(f"{item['en'].ljust(35)} | {str(item['count']).ljust(6)} | {item['zh']}")
        report.append("")
    try:
        _ensure_txt_dir()
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(report))
        out(f"âœ… è³‡æ–™å¤¾å ±å‘Šå·²ç”Ÿæˆï¼š{out_path}")
        if open_after and os.name == 'nt':
            os.startfile(out_path)
        return True
    except Exception as e:
        out(f"âš ï¸ å¯«å…¥å ±å‘Šå¤±æ•—: {e}")
        return False


def generate_file_report(folder_path, report_file=None, db_path=None, log_callback=None, open_after=True):
    """é€æª”æ¨™ç±¤åˆ†é¡å ±å‘Šï¼šé‡å°æ¯å€‹ .txt æª”æ¡ˆï¼Œåˆ—å‡ºå…¶æ¨™ç±¤ä¸¦æŒ‰åˆ†é¡æ’åº"""
    def out(msg):
        if log_callback:
            log_callback(msg)
        else:
            print(msg)
    path = Path(folder_path)
    out("ğŸ“‚ é‡æ–°è¼‰å…¥ JSON è³‡æ–™åº«ä»¥ç¢ºä¿ç‚ºæœ€æ–°...")
    db = load_tag_database(db_path)
    if not path.exists():
        out(f"âŒ æ‰¾ä¸åˆ°è·¯å¾‘: {folder_path}")
        return False
    txt_files = sorted(path.rglob('*.txt'), key=lambda p: p.name)
    if not txt_files:
        out("âŒ æ­¤è³‡æ–™å¤¾æ²’æœ‰æ‰¾åˆ°ä»»ä½• .txt æª”")
        return False
    cat_order = ["è§’è‰²èˆ‡ä½œå“ (Character)"] + [c for c in CATEGORIES.keys() if c != "è§’è‰²èˆ‡ä½œå“ (Character)"] + ["å…¶ä»– (General)"]
    report = [
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
        "â•‘             é€æª”æ¨™ç±¤åˆ†é¡å ±å‘Š (æŒ‰åˆ†é¡æ’åº)                      â•‘",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
        f"  åˆ†æç›®éŒ„: {path.resolve()}",
        f"  åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
    ]
    for txt_path in txt_files:
        f_name = txt_path.name
        tags = extract_tags_from_file(txt_path)
        file_categorized = {cat: [] for cat in cat_order}
        for tag in tags:
            info = db.get(tag, {})
            cat = info.get('category', get_category(tag))
            if cat not in file_categorized:
                cat = "å…¶ä»– (General)"
            zh = info.get('zh_tag', 'æœªç¿»è­¯')
            file_categorized[cat].append(f"{tag}({zh})")
        report.append(f"ğŸ“„ æª”å: [{f_name}]")
        report.append("-" * 70)
        for cat in cat_order:
            if file_categorized[cat]:
                tag_line = ", ".join(file_categorized[cat])
                report.append(f"  â— {cat.ljust(22)}: {tag_line}")
        report.append("\n" + "." * 70 + "\n")
    out_path = str(report_file or TXT_OUTPUT_DIR / "File_Based_Tag_Report.txt")
    try:
        _ensure_txt_dir()
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(report))
        out(f"âœ… é€æª”å ±å‘Šå·²ç”Ÿæˆï¼š{out_path} ({len(txt_files)} å€‹æª”æ¡ˆ)")
        if open_after and os.name == 'nt':
            os.startfile(out_path)
        return True
    except Exception as e:
        out(f"âš ï¸ å¯«å…¥å ±å‘Šå¤±æ•—: {e}")
        return False


def load_tag_data_for_prompt(db_path=None):
    """è®€å– all_characters_tags.json ä¸¦ä¾åˆ†é¡çµ„ç¹”æˆ {åˆ†é¡: [(en, zh), ...]}"""
    path = str(db_path or DB_FILE)
    if not os.path.exists(path):
        return {}
    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    structured = {}
    for item in data:
        cat = item.get('category', 'å…¶ä»– (General)')
        en = item.get('en_tag', '')
        zh = item.get('zh_tag', '')
        if en:
            structured.setdefault(cat, []).append((en, zh))
    return structured


def load_prompt_presets():
    """å¾ prompt_presets.json è¼‰å…¥è§’è‰²å¿«é€Ÿå¥—è£"""
    default = {
        "Key åŸºç¤æ¬¾": ["key (blue archive)", "1girl", "long silver hair", "red eyes", "mechanical halo", "bangs"],
        "å°¼äºå°¼äº åŸºç¤æ¬¾": ["niyaniya (blue archive)", "1girl", "grey hair", "red eyes", "halo", "black coat", "beret"],
    }
    try:
        if PROMPT_PRESETS_FILE.exists():
            with open(PROMPT_PRESETS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, dict):
                    return data
        save_prompt_presets(default)
        return default
    except Exception:
        return default.copy()


def save_prompt_presets(presets):
    """å„²å­˜è§’è‰²å¿«é€Ÿå¥—è£è‡³ prompt_presets.json"""
    try:
        _ensure_data_dir()
        with open(PROMPT_PRESETS_FILE, 'w', encoding='utf-8') as f:
            json.dump(presets, f, ensure_ascii=False, indent=2)
    except Exception:
        pass
